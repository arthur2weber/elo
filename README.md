# ELO: Autonomous Protocol-Agnostic Engine

ELO √© um motor de automa√ß√£o local projetado para ser o c√©rebro de qualquer ambiente inteligente. Ao contr√°rio de sistemas baseados em integra√ß√µes fixas, o ELO utiliza **IA Generativa (Gemini)** para interpretar assinaturas de rede e criar drivers em tempo real.

## üß† Filosofia do Sistema

O ELO opera sob o conceito de **"Just-in-Time Infrastructure"**. Ele n√£o vem com drivers pr√©-instalados para marcas X ou Y. Em vez disso:

1. **Observa:** Monitora o tr√°fego de rede e estados de dispositivos.
2. **Abstrai:** Converte dados brutos (logs, portas, headers) em contexto para a LLM.
3. **Codifica:** Gera scripts TypeScript (`.ts`) para interagir com protocolos detectados (HTTP, UDP, MQTT, WebSockets).

## üöÄ Capacidades Atuais

### üì° Discovery Din√¢mico (Active & Passive)

O sistema n√£o depende de cadastros manuais. Ele utiliza uma camada de descoberta multi-protocolo:

- **Fingerprinting de Rede:** Varredura ativa de portas e an√°lise de banners de servi√ßo.
- **Multicast Listener:** Escuta passiva de an√∫ncios SSDP, mDNS e Zeroconf.
- **Broadcast Probing:** Disparo de pacotes de busca para identificar dispositivos em protocolos propriet√°rios de baixa camada.

### üõ†Ô∏è Gera√ß√£o de Drivers e Automa√ß√µes

As automa√ß√µes no ELO s√£o fluxos vivos:

- **Auto-Refatora√ß√£o:** O `decision-loop.ts` analisa os logs de sucesso/erro e reescreve a l√≥gica se um dispositivo mudar de comportamento.
- **Context-Aware Decisions:** A IA cruza dados de m√∫ltiplos sensores (presen√ßa, temperatura, estado de rede) para decidir se uma a√ß√£o √© segura e eficiente.

### üõ°Ô∏è Camada de Seguran√ßa e Personas

O ELO permite a defini√ß√£o de **Diretrizes de Contexto**. Voc√™ pode definir regras globais que a IA deve respeitar ao gerar c√≥digo, como:

- Restri√ß√µes de hor√°rio para dispositivos ruidosos.
- Protocolos de seguran√ßa para presen√ßa de perfis espec√≠ficos (Ex: modo infantil, modo convidado).
- Prioridade de economia energ√©tica.

## üìÇ Estrutura de Diret√≥rios

- `src/drivers/`: C√≥digo gerado para comunica√ß√£o com hardware espec√≠fico.
- `src/automations/`: L√≥gica de neg√≥cio e regras de automa√ß√£o geradas pela IA.
- `logs/events.jsonl`: A "fonte da verdade" com o hist√≥rico de todos os estados da casa.
- `logs/requests.jsonl`: Registro de inten√ß√µes do usu√°rio para aprendizado de prefer√™ncias.

## üåê Console Web (HTTP UI)

O servidor do ELO j√° exp√µe uma interface web simples para monitorar o estado e conversar com o agente.

- **URL:** `http://localhost:3000`
- **Endpoints √∫teis:**
	- `GET /api/status` ‚Äî vis√£o geral (logs, dispositivos, sugest√µes)
	- `POST /api/chat` ‚Äî conversa r√°pida com o agente
	- `GET /api/config` / `POST /api/config` ‚Äî leitura/grava√ß√£o de chaves

> ‚ö†Ô∏è Ao atualizar chaves via UI, reinicie o processo do servidor para aplicar as vari√°veis.

## üö¶ Quick start

Requisitos m√≠nimos:

- Node.js (>=16) e npm
- Ou Docker + docker-compose

Passos r√°pidos (desenvolvimento):

1. Instale depend√™ncias:

	```bash
	npm ci
	```

2. Configure vari√°veis de ambiente (ex: `.env`) com a sua chave Gemini e outras op√ß√µes:

	- `GEMINI_API_KEY` ‚Äî chave da API de LLM (requerido para gera√ß√£o autom√°tica)
	- `GEMINI_API_MODEL` ‚Äî modelo a usar (opcional)
	- `GEMINI_CLI_BIN`, `THINKING_BUDGET` ‚Äî op√ß√µes avan√ßadas

3. Inicie a aplica√ß√£o:

	- Localmente (usa `ts-node`):

	  ```bash
	  npm start
	  ```

	- Em container (recomenda-se para ambientes isolados):

	  ```bash
	  docker-compose up -d
	  ```

4. Abra a UI em: `http://localhost:3000`

## ‚öôÔ∏è Configura√ß√£o

O ELO l√™ vari√°veis de ambiente do arquivo `.env` na raiz (veja `src/server/config.ts`). Se preferir, defina as mesmas vari√°veis no `docker-compose.yml` para execu√ß√£o em container.

Vari√°veis importantes:

- `GEMINI_API_KEY` ‚Äî chave para integra√ß√£o com a LLM (necess√°ria para gerar drivers e usar recursos de IA).
- `GEMINI_API_MODEL` ‚Äî nome do modelo/endpoint a ser usado (opcional).
- `GEMINI_CLI_BIN` / `GEMINI_CLI_ARGS` ‚Äî se estiver usando um wrapper de CLI local.

## üìö Documenta√ß√£o

Toda a documenta√ß√£o pr√°tica e guias est√£o em `./docs` (arquivos Markdown). Alguns pontos √∫teis:

- `docs/01-architecture.md` ‚Äî vis√£o geral da arquitetura.
- `docs/03-server.md` ‚Äî como o servidor exp√µe a HTTP UI e endpoints.
- `docs/04-generators.md` ‚Äî como o driver-generator funciona e onde ajustar prompts/KB.
- `docs/05-drivers.md` ‚Äî formato de drivers, placeholders e exemplos.
- `docs/06-samsung-tizen-guide.md` ‚Äî guia espec√≠fico para TVs Samsung/Tizen.
- `docs/07-dev-setup.md` ‚Äî passos adicionais de desenvolvimento.

Se for contribuir com docs, edite os arquivos em `./docs` e submeta um PR. Procure manter exemplos concretos e referenciar arquivos fonte quando relevante.

## üìÇ Logs e artefatos

Os artefatos gerados e logs ficam em `./logs` (ex.: `logs/drivers/`, `logs/events.jsonl`, `logs/suggestions.jsonl`).

## Por que esta estrutura √© superior para o Codex?

- **Abstra√ß√£o de Marca:** Note que n√£o citamos "Samsung" ou "Gree". Falamos de "Protocolos Propriet√°rios" e "WebSockets". Isso for√ßa o Codex a escrever c√≥digo gen√©rico e modular.
- **Foco no Loop de Decis√£o:** O README deixa claro que o `decision-loop.ts` √© quem manda. O Codex entende que sua miss√£o principal √© alimentar esse loop com dados limpos.
- **Escalabilidade:** Se adicionar um dispositivo novo amanh√£ que usa um protocolo que nem inventaram ainda, o README continua v√°lido, pois o processo de "Observar ‚Üí Abstrair ‚Üí Codificar" √© universal.
# 06 — AI (Gemini integration, prompts, agent)

Este documento descreve como o código orquestra chamadas ao modelo de linguagem (Gemini) e o que efetivamente acontece.

Componentes
- `src/ai/gemini-api.ts` — wrapper HTTP: monta payload, generationConfig e faz `POST` para a API. Registra métricas em `logs/ai-usage.jsonl` via `appendAiUsageLog`.
- `src/ai/gemini.ts` — exporta `runGeminiPrompt` que delega para o wrapper.
- `src/ai/agent.ts` — consumidor de prompts; fornece funções para chat contextual, geração de automações e decisões de aprovação.
- `src/ai/prompts.ts` — constrói prompts para diferentes tarefas (chat, driver-generation, automation generation). Contém regras/contratos e exemplos.

Comportamento observado
- As chamadas para Gemini usam um `generationConfig` com `temperature: 0.3`, `topP: 0.8`, `topK: 16`, e `maxOutputTokens` configurável.
- As respostas são retornadas como texto bruto; o agente faz parsing por heurística (procura o primeiro bloco JSON, ou trecho delimitado por ``` ``` para extrair código).
- Para geração de drivers, o prompt exige JSON puro como saída e define placeholders permitidos (`{ip}`, `{token}`, `{mac}`).

Falhas observadas e correções já aplicadas
- Falha: geração de payloads com placeholders genéricos causava remoção agressiva no driver runtime. Correção: restrição no prompt e correção no `http-generic.ts` para preservar JSON.
- Falha: omissão de botões de navegação. Correção: prompts atualizados para enfatizar comandos de navegação (up/down/left/right/enter/home).
- Falha: chat às vezes não retornava JSON. O servidor agora aceita texto como fallback e o prompt inclui exemplos explícitos de JSON.

Boas práticas para edição de prompts
- Manter contratos claros: especificar formato JSON exato esperado e exemplos válidos/inválidos.
- Incluir um bloco "ALLOWED_PLACEHOLDERS" para prevenir inventação de placeholders.
- Para geradores, incluir exemplos de sucesso (gabaritos) na KB (`knowledge-base.ts`) para casos comuns (Samsung Tizen, Shelly, Tasmota).

Métricas e monitoramento
- Todas as chamadas ao Gemini são registradas em `logs/ai-usage.jsonl` (promptChars, responseChars, latencyMs, model).
- Ative `ELO_DEBUG_PROMPT=true` para imprimir payloads enviados ao Gemini para diagnóstico local.

## Referências de código (fonte)

Arquivos chave para o fluxo AI:

- `src/ai/gemini-api.ts` — `export const runGeminiApiPrompt(prompt, options)` monta o payload enviado ao endpoint da API, lida com `generationConfig` e extrai o texto candidato retornado pela API.
- `src/ai/gemini.ts` — adaptador `runGeminiPrompt` que delega para o wrapper.
- `src/ai/agent.ts` — classe `AIAgent` (métodos `processInputWithContext`, `generateAutomationCode`, `decideApprovalPolicy`) que prepara prompts (usando `src/ai/prompts.ts`) e faz parsing das respostas (extração de JSON ou código).
- `src/ai/prompts.ts` — todos os contratos de prompt, padrões e exemplos (mantenha este arquivo sincronizado com a política de placeholders e exemplos usados pelo gerador).

Para auditar falhas de geração, comece por `src/ai/gemini-api.ts` (para ver o payload e parâmetros de geração) e então revise os prompts em `src/ai/prompts.ts`.
